{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mount to MongoDB\n",
    "MongoDB is a useful NoSQL database for storing large amounts of JSON. We can run this on a server, or locally if we have enough drive space. \n",
    "\n",
    "Compared with scanning the data files, MongoDB can allow us to index the data, this way we can pick which specific data we want to look at more easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import json\n",
    "import gzip\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise client class for interacting with db\n",
    "client = pymongo.MongoClient()\n",
    "# create or open database\n",
    "db = client['unpaywall']\n",
    "# create or open collection (table) within database\n",
    "collection = db['snapshot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "# collection.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'C:\\Users\\aday\\OneDrive - SAGE Publishing\\DATA\\Unpaywall\\unpaywall_snapshot_2021-02-18T160139.jsonl.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upserting Vs Inserting\n",
    "- Inserting is where we simply put a new record into our database. It is the fastest way to CREATE our database from scratch in 1 go. You can also use batch processes to do this faster (but below we only insert one at a time). \n",
    "- If we want to add to our database (i.e. create in multiple gos), or update it with a new snapshot, then we can upsert instead. This way, we check to see if our document already exists in the data. \n",
    "  - If not, then we insert it.\n",
    "  - If so, and our document has been updated, then we update the document in our database.\n",
    "  - If both documents are identical, we skip the update. \n",
    "\n",
    "Upserting avoids unecessarily writing the the database, which can be slow. __Note__ that to upsert data, you need to have an index on the doi field. This is done in the cell below the next one. Be aware that, the larger your collection, the slower creating the index will be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-22 13:42:14.432223 20000000 records written to Mongo\n",
      "2021-02-22 13:53:17.333130 21000000 records written to Mongo\n",
      "2021-02-22 14:05:10.295292 22000000 records written to Mongo\n",
      "2021-02-22 14:16:18.747638 23000000 records written to Mongo\n",
      "2021-02-22 14:26:53.700182 24000000 records written to Mongo\n",
      "2021-02-22 14:38:20.724211 25000000 records written to Mongo\n",
      "2021-02-22 14:51:38.389285 26000000 records written to Mongo\n",
      "2021-02-22 15:08:15.265702 27000000 records written to Mongo\n",
      "2021-02-22 15:25:05.560059 28000000 records written to Mongo\n",
      "2021-02-22 15:40:38.005620 29000000 records written to Mongo\n",
      "2021-02-22 15:54:36.483126 30000000 records written to Mongo\n",
      "2021-02-22 16:06:17.736212 31000000 records written to Mongo\n",
      "2021-02-22 16:16:32.765132 32000000 records written to Mongo\n",
      "2021-02-22 16:26:43.826653 33000000 records written to Mongo\n",
      "2021-02-22 16:37:00.626381 34000000 records written to Mongo\n",
      "2021-02-22 16:47:33.917943 35000000 records written to Mongo\n",
      "2021-02-22 16:57:46.581930 36000000 records written to Mongo\n",
      "2021-02-22 17:08:13.267386 37000000 records written to Mongo\n",
      "2021-02-22 17:18:46.166790 38000000 records written to Mongo\n",
      "2021-02-22 17:29:40.904655 39000000 records written to Mongo\n",
      "2021-02-22 17:40:35.421822 40000000 records written to Mongo\n",
      "2021-02-22 17:51:33.888294 41000000 records written to Mongo\n",
      "2021-02-22 18:02:23.061640 42000000 records written to Mongo\n",
      "2021-02-22 18:13:15.840181 43000000 records written to Mongo\n",
      "2021-02-22 18:24:05.695214 44000000 records written to Mongo\n",
      "2021-02-22 18:34:43.071538 45000000 records written to Mongo\n",
      "2021-02-22 18:45:07.078299 46000000 records written to Mongo\n",
      "2021-02-22 18:55:46.161137 47000000 records written to Mongo\n",
      "2021-02-22 19:06:33.347032 48000000 records written to Mongo\n",
      "2021-02-22 19:17:14.002028 49000000 records written to Mongo\n",
      "2021-02-22 19:27:54.350194 50000000 records written to Mongo\n",
      "2021-02-22 19:38:34.594642 51000000 records written to Mongo\n",
      "2021-02-22 19:49:21.701327 52000000 records written to Mongo\n",
      "2021-02-22 20:00:07.672287 53000000 records written to Mongo\n",
      "2021-02-22 20:10:55.246508 54000000 records written to Mongo\n",
      "2021-02-22 20:21:59.865202 55000000 records written to Mongo\n",
      "2021-02-22 20:33:06.653540 56000000 records written to Mongo\n",
      "2021-02-22 20:43:54.770584 57000000 records written to Mongo\n",
      "2021-02-22 20:54:39.789397 58000000 records written to Mongo\n",
      "2021-02-22 21:05:30.397843 59000000 records written to Mongo\n",
      "2021-02-22 21:16:26.042835 60000000 records written to Mongo\n",
      "2021-02-22 21:26:55.749228 61000000 records written to Mongo\n",
      "2021-02-22 21:37:44.313799 62000000 records written to Mongo\n",
      "2021-02-22 21:48:34.746310 63000000 records written to Mongo\n",
      "2021-02-22 21:59:23.549152 64000000 records written to Mongo\n",
      "2021-02-22 22:10:07.002738 65000000 records written to Mongo\n",
      "2021-02-22 22:20:36.107734 66000000 records written to Mongo\n",
      "2021-02-22 22:31:16.776553 67000000 records written to Mongo\n",
      "2021-02-22 22:41:59.978899 68000000 records written to Mongo\n",
      "2021-02-22 22:52:29.500476 69000000 records written to Mongo\n",
      "2021-02-22 23:03:20.336908 70000000 records written to Mongo\n",
      "2021-02-22 23:14:35.637452 71000000 records written to Mongo\n",
      "2021-02-22 23:25:37.347958 72000000 records written to Mongo\n",
      "2021-02-22 23:36:33.533384 73000000 records written to Mongo\n",
      "2021-02-22 23:47:44.789406 74000000 records written to Mongo\n",
      "2021-02-22 23:58:27.550475 75000000 records written to Mongo\n",
      "2021-02-23 00:09:29.613341 76000000 records written to Mongo\n",
      "2021-02-23 00:20:14.411221 77000000 records written to Mongo\n",
      "2021-02-23 00:31:15.282296 78000000 records written to Mongo\n",
      "2021-02-23 00:42:18.008304 79000000 records written to Mongo\n",
      "2021-02-23 00:53:19.521269 80000000 records written to Mongo\n",
      "2021-02-23 01:03:36.859068 81000000 records written to Mongo\n",
      "2021-02-23 01:14:01.246693 82000000 records written to Mongo\n",
      "2021-02-23 01:23:35.073373 83000000 records written to Mongo\n",
      "2021-02-23 01:33:32.546450 84000000 records written to Mongo\n",
      "2021-02-23 01:43:40.551453 85000000 records written to Mongo\n",
      "2021-02-23 01:53:17.754107 86000000 records written to Mongo\n",
      "2021-02-23 02:03:10.235009 87000000 records written to Mongo\n",
      "2021-02-23 02:13:44.817453 88000000 records written to Mongo\n",
      "2021-02-23 02:23:44.964761 89000000 records written to Mongo\n",
      "2021-02-23 02:33:47.802125 90000000 records written to Mongo\n",
      "2021-02-23 02:44:10.099789 91000000 records written to Mongo\n",
      "2021-02-23 02:54:10.139667 92000000 records written to Mongo\n",
      "2021-02-23 03:03:58.777052 93000000 records written to Mongo\n",
      "2021-02-23 03:12:42.621461 94000000 records written to Mongo\n",
      "2021-02-23 03:20:44.688167 95000000 records written to Mongo\n",
      "2021-02-23 03:27:52.104352 96000000 records written to Mongo\n",
      "2021-02-23 03:31:04.420952 97000000 records written to Mongo\n",
      "2021-02-23 03:34:13.209619 98000000 records written to Mongo\n",
      "2021-02-23 03:37:11.811947 99000000 records written to Mongo\n",
      "2021-02-23 03:40:12.130233 100000000 records written to Mongo\n",
      "2021-02-23 03:43:13.502880 101000000 records written to Mongo\n",
      "2021-02-23 03:46:12.137711 102000000 records written to Mongo\n",
      "2021-02-23 03:49:10.867529 103000000 records written to Mongo\n",
      "2021-02-23 03:52:09.920371 104000000 records written to Mongo\n",
      "2021-02-23 03:55:08.475220 105000000 records written to Mongo\n",
      "2021-02-23 03:58:09.792345 106000000 records written to Mongo\n",
      "2021-02-23 04:01:15.552061 107000000 records written to Mongo\n",
      "2021-02-23 04:04:20.193153 108000000 records written to Mongo\n",
      "2021-02-23 04:07:24.878003 109000000 records written to Mongo\n",
      "2021-02-23 04:10:29.342830 110000000 records written to Mongo\n",
      "2021-02-23 04:13:29.072314 111000000 records written to Mongo\n",
      "2021-02-23 04:16:30.239650 112000000 records written to Mongo\n",
      "2021-02-23 04:19:32.765507 113000000 records written to Mongo\n",
      "2021-02-23 04:22:32.167697 114000000 records written to Mongo\n",
      "2021-02-23 04:25:33.849474 115000000 records written to Mongo\n",
      "2021-02-23 04:28:30.129507 116000000 records written to Mongo\n",
      "2021-02-23 04:31:32.443783 117000000 records written to Mongo\n",
      "2021-02-23 04:34:28.566913 118000000 records written to Mongo\n",
      "2021-02-23 04:37:16.980713 119000000 records written to Mongo\n",
      "2021-02-23 04:40:05.666533 120000000 records written to Mongo\n",
      "2021-02-23 04:42:56.598834 121000000 records written to Mongo\n",
      "2021-02-23 04:45:45.136907 122000000 records written to Mongo\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gzip\n",
    "batch_size = 1000\n",
    "batch = []\n",
    "with gzip.open(filepath,'rb') as f:\n",
    "    \n",
    "    for i,line in enumerate(f):\n",
    "        \n",
    "        \n",
    "        # INSERT DATA\n",
    "#         if i<20000000:\n",
    "#             continue\n",
    "#         else:\n",
    "#             try:\n",
    "#                 collection.insert_one(json.loads(line))\n",
    "#             except Exception as e:\n",
    "#                 print('Error: ', e)\n",
    "#                 print('Bad line: ', line)\n",
    "#                 print()\n",
    "#         if i%1000000==0:\n",
    "#             print(i, 'records done')\n",
    "\n",
    "\n",
    "        ## UPSERT DATA\n",
    "        line = json.loads(line)\n",
    "        doi = line['doi']\n",
    "        \n",
    "        \n",
    "        batch.append(pymongo.UpdateOne({'doi':doi}, {'$set':line}, upsert = True))\n",
    "        try:\n",
    "            if i%batch_size==0:\n",
    "                collection.bulk_write(batch)\n",
    "                batch = []\n",
    "                if i%(1000*batch_size)==0:\n",
    "                    print(datetime.datetime.now(),i, 'records written to Mongo')\n",
    "        except Exception as e:\n",
    "            print('ERROR', e)\n",
    "            print('Batch write failed! Try items individually')\n",
    "            for item in batch:\n",
    "                try:\n",
    "                    collection.bulk_write([item])\n",
    "                except Exception as e:\n",
    "                    print('Error: ', e)\n",
    "                    print('ITEM:', item)\n",
    "                batch = []\n",
    "    # Final batch\n",
    "    if len(batch)>0:\n",
    "        try:\n",
    "            collection.bulk_write(batch)\n",
    "        except:\n",
    "            print('Batch write failed! Try items individually')\n",
    "            for item in batch:\n",
    "                try:\n",
    "                    collection.write(item)\n",
    "                except Exception as e:\n",
    "                    print('Error: ', e)\n",
    "                    print('ITEM:', item)\n",
    "    else:\n",
    "        print('No records to write. Skipping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index (or simply confirm it's there already)\n",
    "collection.create_index([( 'doi', pymongo.ASCENDING )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.create_index([( 'year', pymongo.ASCENDING )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.create_index([( 'publisher', pymongo.ASCENDING )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check\n",
    "How quickly can we retrieve an item by its doi? Pick any DOI you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5fbc111ce91f8c83cf0fc86c'),\n",
       " 'doi': '10.1080/21645515.2017.1330236',\n",
       " 'year': 2017,\n",
       " 'genre': 'journal-article',\n",
       " 'is_oa': True,\n",
       " 'title': 'Advancements in DNA vaccine vectors, non-mechanical delivery methods, and molecular adjuvants to increase immunogenicity',\n",
       " 'doi_url': 'https://doi.org/10.1080/21645515.2017.1330236',\n",
       " 'updated': '2021-01-17T06:00:02.039312',\n",
       " 'oa_status': 'hybrid',\n",
       " 'publisher': 'Informa UK Limited',\n",
       " 'z_authors': [{'given': 'John J.',\n",
       "   'family': 'Suschak',\n",
       "   'sequence': 'first',\n",
       "   'affiliation': [{'name': 'U.S. Army Medical Research Institute of Infectious Diseases, Fort Detrick, MD, USA'}]},\n",
       "  {'given': 'James A.',\n",
       "   'family': 'Williams',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': [{'name': 'Nature Technology Corporation, Lincoln, NE, USA'}]},\n",
       "  {'given': 'Connie S.',\n",
       "   'family': 'Schmaljohn',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': [{'name': 'U.S. Army Medical Research Institute of Infectious Diseases, Fort Detrick, MD, USA'}]}],\n",
       " 'is_paratext': False,\n",
       " 'journal_name': 'Human Vaccines & Immunotherapeutics',\n",
       " 'oa_locations': [{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/21645515.2017.1330236?needAccess=true',\n",
       "   'pmh_id': None,\n",
       "   'is_best': True,\n",
       "   'license': 'cc-by',\n",
       "   'oa_date': '2017-06-12',\n",
       "   'updated': '2020-09-19T20:32:15.963111',\n",
       "   'version': 'publishedVersion',\n",
       "   'evidence': 'open (via free pdf)',\n",
       "   'host_type': 'publisher',\n",
       "   'endpoint_id': None,\n",
       "   'url_for_pdf': 'https://www.tandfonline.com/doi/pdf/10.1080/21645515.2017.1330236?needAccess=true',\n",
       "   'url_for_landing_page': 'https://doi.org/10.1080/21645515.2017.1330236',\n",
       "   'repository_institution': None},\n",
       "  {'url': 'http://europepmc.org/articles/pmc5718814?pdf=render',\n",
       "   'pmh_id': 'oai:europepmc.org:KTzQgHcHG2PQNDNuv9aC',\n",
       "   'is_best': False,\n",
       "   'license': 'cc-by-nc-nd',\n",
       "   'oa_date': None,\n",
       "   'updated': None,\n",
       "   'version': 'publishedVersion',\n",
       "   'evidence': 'oa repository (via OAI-PMH doi match)',\n",
       "   'host_type': 'repository',\n",
       "   'endpoint_id': 'b5e840539009389b1a6',\n",
       "   'url_for_pdf': 'http://europepmc.org/articles/pmc5718814?pdf=render',\n",
       "   'url_for_landing_page': 'http://europepmc.org/articles/pmc5718814',\n",
       "   'repository_institution': 'PubMed Central - Europe PMC'},\n",
       "  {'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5718814',\n",
       "   'pmh_id': None,\n",
       "   'is_best': False,\n",
       "   'license': None,\n",
       "   'oa_date': None,\n",
       "   'updated': '2021-02-15T13:12:18.597051',\n",
       "   'version': 'publishedVersion',\n",
       "   'evidence': 'oa repository (via pmcid lookup)',\n",
       "   'host_type': 'repository',\n",
       "   'endpoint_id': None,\n",
       "   'url_for_pdf': None,\n",
       "   'url_for_landing_page': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5718814',\n",
       "   'repository_institution': None}],\n",
       " 'data_standard': 2,\n",
       " 'journal_is_oa': False,\n",
       " 'journal_issns': '2164-5515,2164-554X',\n",
       " 'journal_issn_l': '2164-5515',\n",
       " 'published_date': '2017-06-12',\n",
       " 'best_oa_location': {'url': 'https://www.tandfonline.com/doi/pdf/10.1080/21645515.2017.1330236?needAccess=true',\n",
       "  'pmh_id': None,\n",
       "  'is_best': True,\n",
       "  'license': 'cc-by',\n",
       "  'oa_date': '2017-06-12',\n",
       "  'updated': '2020-09-19T20:32:15.963111',\n",
       "  'version': 'publishedVersion',\n",
       "  'evidence': 'open (via free pdf)',\n",
       "  'host_type': 'publisher',\n",
       "  'endpoint_id': None,\n",
       "  'url_for_pdf': 'https://www.tandfonline.com/doi/pdf/10.1080/21645515.2017.1330236?needAccess=true',\n",
       "  'url_for_landing_page': 'https://doi.org/10.1080/21645515.2017.1330236',\n",
       "  'repository_institution': None},\n",
       " 'first_oa_location': {'url': 'https://www.tandfonline.com/doi/pdf/10.1080/21645515.2017.1330236?needAccess=true',\n",
       "  'pmh_id': None,\n",
       "  'is_best': True,\n",
       "  'license': 'cc-by',\n",
       "  'oa_date': '2017-06-12',\n",
       "  'updated': '2020-09-19T20:32:15.963111',\n",
       "  'version': 'publishedVersion',\n",
       "  'evidence': 'open (via free pdf)',\n",
       "  'host_type': 'publisher',\n",
       "  'endpoint_id': None,\n",
       "  'url_for_pdf': 'https://www.tandfonline.com/doi/pdf/10.1080/21645515.2017.1330236?needAccess=true',\n",
       "  'url_for_landing_page': 'https://doi.org/10.1080/21645515.2017.1330236',\n",
       "  'repository_institution': None},\n",
       " 'journal_is_in_doaj': False,\n",
       " 'has_repository_copy': True,\n",
       " 'oa_locations_embargoed': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "collection.find_one({'doi': '10.1080/21645515.2017.1330236'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
